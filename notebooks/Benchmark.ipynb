{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3122a81c-283c-4971-ac2a-c4c65a624ed9",
   "metadata": {},
   "source": [
    "# `quickmt` Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea56cf71-06ed-4ee0-bfaf-c202fd8c2eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "import datasets\n",
    "from fire import Fire\n",
    "from quickmt import M2m100Translator, NllbTranslator, OpusmtTranslator, Translator\n",
    "from sacrebleu import BLEU, CHRF, TER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dec07dd-3e56-4c74-b0c9-5ac445041b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = BLEU()\n",
    "chrf = CHRF()\n",
    "ter = TER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "467bb6fc-6d4d-4c69-a9ba-ff52f2259c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = \"it\"\n",
    "tgt_lang = \"en\"\n",
    "src_lang_flores = \"ita_Latn\"\n",
    "tgt_lang_flores = \"eng_Latn\"\n",
    "\n",
    "quickmt_model_path = \"../../quickmt-models/quickmt-en-ja\"\n",
    "\n",
    "opusmt_model_path = \"../../ct2-models/opus-mt-it-en-ct2\"\n",
    "opusmt_model_string = \"Helsinki-NLP/opus-mt-it-en\"\n",
    "\n",
    "nllb600_model_path = \"../../ct2-models/nllb-200-distilled-600M-ct2\"\n",
    "nllb1b_model_path = \"../../ct2-models/nllb-200-distilled-1.3B-ct2\"\n",
    "m2m100_418m_model_path = \"../../ct2-models/m2m100_418-ct2/\"\n",
    "m2m100_1b_model_path = \"../../ct2-models/m2m100_1.2B-ct2/\"\n",
    "\n",
    "compute_device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7ffe9f-f9bf-4349-843c-4e4308b5d28c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    flores = datasets.load_dataset(\n",
    "        \"facebook/flores\",\n",
    "        f\"{src_lang_flores}-{tgt_lang_flores}\",\n",
    "    )\n",
    "except:\n",
    "    flores = datasets.load_dataset(\n",
    "        \"facebook/flores\",\n",
    "        f\"{tgt_lang_flores}-{src_lang_flores}\",\n",
    "    )\n",
    "\n",
    "src = []\n",
    "ref = []\n",
    "for i in flores[\"devtest\"]:\n",
    "    src.append(i[f\"sentence_{src_lang_flores}\"])\n",
    "    ref.append(i[f\"sentence_{tgt_lang_flores}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e44c7a8-405f-497c-bbde-8b6bc319c660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lo studio è ancora in fase iniziale, come dichiarato cautelativamente dal dottor Ehud Ur, professore di medicina alla Dalhousie University di Halifax, Nuova Scozia, e direttore del dipartimento clinico e scientifico della Canadian Diabetes Association.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "366bdc3a-a8e5-4b98-8179-111e53196809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(f\"flores.{src_lang}\", \"wt\") as myfile:\n",
    "    myfile.write(\"\".join([i + \"\\n\" for i in src]))\n",
    "with open(f\"flores.{tgt_lang}\", \"wt\") as myfile:\n",
    "    myfile.write(\"\".join([i + \"\\n\" for i in ref]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc5a3c-4794-4fa4-9048-0fb472d9ecb8",
   "metadata": {},
   "source": [
    "## Quickmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d91cc6a3-7085-4b51-b383-d48dd46b023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(model_path=quickmt_model_path, device=compute_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1067a104-d2a1-4a32-b257-b77019658b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time: 0.036295413970947266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ノバスコシア州ハリファックスのダルハウジー大学の医学教授で、カナダ糖尿病協会の臨床および科学部門の議長であるEhud Ur博士は、研究はまだ初期段階にあると警告しました。'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(src[1], beam_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4bc9c867-9ce7-42b8-9f40-e5be0298b065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time: 0.05721259117126465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ehud Ur博士は、ノバスコシア州ハリファックスのダルハウジー大学医学部の教授で、カナダ糖尿病協会の臨床および科学的部門の責任者は、研究はまだその初期の段階であると言いました。'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(src[1], sampling_temperature=1.2, beam_size=1, sampling_topk=50, sampling_topp=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62ab5a53-8954-4971-a16e-26915c6ced23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time: 1.2255754470825195\n",
      "CPU times: user 4.3 s, sys: 1.51 ms, total: 4.3 s\n",
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mt = translator(src, max_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2abf3f12-ac9c-421b-aac9-532de38411c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 3.63 3.7/3.9/3.8/3.2 (BP = 1.000 ratio = 1.800 hyp_len = 2099 ref_len = 1166)\n",
      "chrF2 = 42.04\n",
      "TER = 136.91\n"
     ]
    }
   ],
   "source": [
    "print(bleu.corpus_score(mt, [ref]))\n",
    "print(chrf.corpus_score(mt, [ref]))\n",
    "print(ter.corpus_score(mt, [ref]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97bddcc7-4e9b-4efa-bd7c-c1f71978d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"quickmt.{tgt_lang}\", \"wt\") as myfile:\n",
    "    myfile.write(\"\".join([i + \"\\n\" for i in mt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a730621-06cf-4c6f-b4eb-12953cf9efe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Fetching 5 files: 100%|████████████████████████| 5/5 [00:00<00:00, 48998.88it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/home/mark/miniforge3/envs/comet/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████████████| 32/32 [00:04<00:00,  7.74it/s]\n",
      "quickmt.ja\tscore: 0.8908\n"
     ]
    }
   ],
   "source": [
    "! ~/miniforge3/envs/comet/bin/comet-score -s flores.{src_lang} -r flores.{tgt_lang} -t quickmt.{tgt_lang} --batch_size 32 --only_system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ddff0a-9d81-4873-9794-87fa5e9de031",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e309f9ed-9a62-470c-9be6-d8923dd9e8b6",
   "metadata": {},
   "source": [
    "## OpusMT\n",
    "\n",
    "Be sure to export the models to `ctranslate2` format first, e.g.\n",
    "\n",
    "```bash\n",
    "ct2-transformers-converter --model Helsinki-NLP/opus-mt-en-de --output_dir ./ct2-models/opus-mt-en-de-ct2\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5a72561-6e4f-4201-92ea-02e21b24d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = OpusmtTranslator(\n",
    "    model_path=opusmt_model_path,\n",
    "    model_string=opusmt_model_string,\n",
    "    device=compute_device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61ce982e-2f77-41e3-9b55-7c6bfd5e8903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time: 0.5747060775756836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"We have four-month-old mice who were diabetics and now they are no longer diabetics,\" he added.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(src[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7d34ff3-dc62-40ed-a4c0-028693ea8040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time: 114.44406247138977\n",
      "CPU times: user 7min 33s, sys: 1.9 s, total: 7min 35s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mt = translator(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f328ec30-d8ee-4f48-930f-6af04f8c7629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 29.48 62.1/36.1/22.8/14.8 (BP = 1.000 ratio = 1.069 hyp_len = 26430 ref_len = 24721)\n",
      "chrF2 = 59.96\n",
      "TER = 59.48\n"
     ]
    }
   ],
   "source": [
    "print(bleu.corpus_score(mt, [ref]))\n",
    "print(chrf.corpus_score(mt, [ref]))\n",
    "print(ter.corpus_score(mt, [ref]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2204c3f-de17-4295-a19d-0758b6a62608",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"opusmt.{tgt_lang}\", \"wt\") as myfile:\n",
    "    myfile.write(\"\".join([i + \"\\n\" for i in mt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcb6a52e-3a8f-4acd-a363-1c7aeaeab033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Fetching 5 files: 100%|████████████████████████| 5/5 [00:00<00:00, 36095.56it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/home/mark/miniforge3/envs/comet/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████████████| 32/32 [00:05<00:00,  5.37it/s]\n",
      "opusmt.ja\tscore: 0.6291\n"
     ]
    }
   ],
   "source": [
    "! ~/miniforge3/envs/comet/bin/comet-score -s flores.{src_lang} -r flores.{tgt_lang} -t opusmt.{tgt_lang} --batch_size 32 --only_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319e54f-376d-4107-b3ae-5a7615424b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5e47e29-c72e-4f28-9bc6-4165b7dca0fb",
   "metadata": {},
   "source": [
    "## NLLB-600M\n",
    "\n",
    "Be sure to export the models to `ctranslate2` format first, e.g.\n",
    "\n",
    "```bash\n",
    "ct2-transformers-converter --model facebook/nllb-200-distilled-600M --output_dir ../ct2-models/nllb-200-distilled-600M-ct2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5aded02-1c88-4d75-8c4f-d1cda735df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = NllbTranslator(model_path=nllb600_model_path, device=compute_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b65c1ecd-d7a8-48b6-9ee0-747a9413b71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time: 22.75724220275879\n",
      "CPU times: user 40.5 s, sys: 58.5 ms, total: 40.5 s\n",
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mt = translator(src, src_lang=src_lang_flores, tgt_lang=tgt_lang_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ddf19ea9-5259-464a-b83e-568d6909f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 33.49 65.1/40.0/26.7/18.1 (BP = 1.000 ratio = 1.037 hyp_len = 25636 ref_len = 24721)\n",
      "chrF2 = 61.97\n",
      "TER = 54.36\n"
     ]
    }
   ],
   "source": [
    "print(bleu.corpus_score(mt, [ref]))\n",
    "print(chrf.corpus_score(mt, [ref]))\n",
    "print(ter.corpus_score(mt, [ref]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea20271c-abd5-4279-adc3-749644635e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"nllb-600m.{tgt_lang}\", \"wt\") as myfile:\n",
    "    myfile.write(\"\".join([i + \"\\n\" for i in mt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3003ac99-9ae9-49e5-85d9-11210b7d1de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Fetching 5 files: 100%|████████████████████████| 5/5 [00:00<00:00, 67216.41it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/home/mark/miniforge3/envs/comet/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████████████| 32/32 [00:03<00:00,  8.86it/s]\n",
      "nllb-600m.en\tscore: 0.8739\n"
     ]
    }
   ],
   "source": [
    "! ~/miniforge3/envs/comet/bin/comet-score -s flores.{src_lang} -r flores.{tgt_lang} -t nllb-600m.{tgt_lang} --batch_size 32 --only_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308eac41-d7b7-4b93-b753-7c1c2a6f56e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28072ed5-f0db-4e07-aeeb-adbe236cd6a5",
   "metadata": {},
   "source": [
    "## NLLB-1.3B\n",
    "\n",
    "Be sure to export the models to `ctranslate2` format first, e.g.\n",
    "\n",
    "```bash\n",
    "ct2-transformers-converter --model facebook/nllb-200-distilled-1.3B --output_dir ../ct2-models/nllb-200-distilled-1.3B-ct2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e42d0d09-d5a6-49c9-b976-b441916ca173",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = NllbTranslator(model_path=nllb1b_model_path, device=compute_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6eba06a2-1852-40e1-9fdf-67661b907fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time: 40.09129095077515\n",
      "CPU times: user 58.4 s, sys: 111 ms, total: 58.5 s\n",
      "Wall time: 40.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mt = translator(src, src_lang=src_lang_flores, tgt_lang=tgt_lang_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5174f7a-578f-4ce6-aac5-04ea0686b0a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 34.97 66.4/41.7/28.1/19.3 (BP = 1.000 ratio = 1.035 hyp_len = 25598 ref_len = 24721)\n",
      "chrF2 = 63.23\n",
      "TER = 52.60\n"
     ]
    }
   ],
   "source": [
    "print(bleu.corpus_score(mt, [ref]))\n",
    "print(chrf.corpus_score(mt, [ref]))\n",
    "print(ter.corpus_score(mt, [ref]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "176cdc04-130f-4c12-82ae-04ed54bc22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"nllb-1.3b.{tgt_lang}\", \"wt\") as myfile:\n",
    "    myfile.write(\"\".join([i + \"\\n\" for i in mt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45237b2a-0603-4034-a4e5-adf5c35b3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "del mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ddc5ce4-2af7-43f0-a3a1-0bd0be747e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Fetching 5 files: 100%|████████████████████████| 5/5 [00:00<00:00, 99864.38it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/home/mark/miniforge3/envs/comet/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████████████| 64/64 [00:03<00:00, 16.40it/s]\n",
      "nllb-1.3b.en\tscore: 0.8814\n"
     ]
    }
   ],
   "source": [
    "! ~/miniforge3/envs/comet/bin/comet-score -s flores.{src_lang} -r flores.{tgt_lang} -t nllb-1.3b.{tgt_lang} --batch_size 16 --only_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217aeb14-5f2c-488a-aef4-f46224cc99e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96d99538-8f7b-44ea-9d16-0026c162cc3f",
   "metadata": {},
   "source": [
    "## M2M100-418M\n",
    "\n",
    "Be sure to export the models to `ctranslate2` format first, e.g.\n",
    "\n",
    "```bash\n",
    "ct2-transformers-converter --model facebook/m2m100_418M --output_dir ../ct2-models/m2m100_418-ct2/\n",
    "ct2-transformers-converter --model facebook/m2m100_1.2B --output_dir ../ct2-models/m2m100_1.2B-ct2/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "774bf94d-25a4-4988-8dbe-e6a4203e1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = M2m100Translator(model_path=m2m100_418m_model_path, device=compute_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1f71877-1238-411a-aba7-f5c0709d46c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time: 17.606944799423218\n",
      "CPU times: user 38.7 s, sys: 57.8 ms, total: 38.8 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mt = translator(src, src_lang=src_lang, tgt_lang=tgt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8a91b475-98d1-4e25-af05-f9d8a4434e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 25.92 58.9/32.2/19.6/12.1 (BP = 1.000 ratio = 1.083 hyp_len = 26777 ref_len = 24721)\n",
      "chrF2 = 56.94\n",
      "TER = 63.19\n"
     ]
    }
   ],
   "source": [
    "print(bleu.corpus_score(mt, [ref]))\n",
    "print(chrf.corpus_score(mt, [ref]))\n",
    "print(ter.corpus_score(mt, [ref]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34be7063-9fdb-404c-a760-d7b4f7f3d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"m2m100-418m.{tgt_lang}\", \"wt\") as myfile:\n",
    "    myfile.write(\"\".join([i + \"\\n\" for i in mt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "960c228a-436e-4e91-86c4-235a4aa35b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Fetching 5 files: 100%|███████████████████████| 5/5 [00:00<00:00, 108660.73it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/home/mark/miniforge3/envs/comet/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████████████| 32/32 [00:03<00:00,  8.83it/s]\n",
      "m2m100-418m.en\tscore: 0.8314\n"
     ]
    }
   ],
   "source": [
    "! ~/miniforge3/envs/comet/bin/comet-score -s flores.{src_lang} -r flores.{tgt_lang} -t m2m100-418m.{tgt_lang} --batch_size 32 --only_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b132a8af-5944-4481-9f4e-ba7fc48a21af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "425cff99-a65b-4df2-8e8a-b265cc148375",
   "metadata": {},
   "source": [
    "## M2M100-1.2B\n",
    "\n",
    "Be sure to export the models to `ctranslate2` format first, e.g.\n",
    "\n",
    "```bash\n",
    "ct2-transformers-converter --model facebook/m2m100_1.2B --output_dir ../ct2-models/m2m100_1.2B-ct2/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74b74474-235d-4406-aecb-5c69f98461f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = M2m100Translator(model_path=m2m100_1b_model_path, device=compute_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e28d0645-3b9f-4596-926d-1e1188a86690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation time: 35.73472595214844\n",
      "CPU times: user 57.7 s, sys: 173 ms, total: 57.9 s\n",
      "Wall time: 38.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mt = translator(src, src_lang=src_lang, tgt_lang=tgt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c1d0d7dd-dcf0-4d5d-bb45-70f0cf96ed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 30.81 63.0/37.3/24.1/15.9 (BP = 1.000 ratio = 1.057 hyp_len = 26122 ref_len = 24721)\n",
      "chrF2 = 60.43\n",
      "TER = 57.38\n"
     ]
    }
   ],
   "source": [
    "print(bleu.corpus_score(mt, [ref]))\n",
    "print(chrf.corpus_score(mt, [ref]))\n",
    "print(ter.corpus_score(mt, [ref]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fa6864f8-87a4-4437-9e8c-eba3dfaf3414",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"m2m100-1.2B.{tgt_lang}\", \"wt\") as myfile:\n",
    "    myfile.write(\"\".join([i + \"\\n\" for i in mt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd26294a-739d-4a11-8606-e0a8a79f012b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "Fetching 5 files: 100%|███████████████████████| 5/5 [00:00<00:00, 121222.66it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/home/mark/miniforge3/envs/comet/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████████████| 32/32 [00:03<00:00,  8.84it/s]\n",
      "m2m100-1.2B.en\tscore: 0.8643\n"
     ]
    }
   ],
   "source": [
    "! ~/miniforge3/envs/comet/bin/comet-score -s flores.{src_lang} -r flores.{tgt_lang} -t m2m100-1.2B.{tgt_lang} --batch_size 32 --only_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30e55f-6bec-474f-b046-24f6b0686c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a1a6552-5f8e-4799-a509-813e07be0e6b",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b628124b-dfdb-44ca-aba0-0050192b4603",
   "metadata": {},
   "source": [
    "| Model                            | chrf2 | bleu    | comet22 | Time (s) |\n",
    "| -------------------------------- | ----- | ------- | ------- | -------- |\n",
    "| quickmt/quickmt-de-en            | 68.83 | 44.20   | 88.88   | 0.90     |\n",
    "| Helsinki-NLP/opus-mt-de-en       | 66.16 | 40.04   | 87.68   | 3.51     |\n",
    "| facebook/m2m100_418M             | 61.86 | 34.27   | 84.52   | 18.1     |\n",
    "| facebook/m2m100_1.2B             | 65.99 | 40.34   | 87.67   | 35.2     |\n",
    "| facebook/nllb-200-distilled-600M | 67.07 | 42.46   | 88.14   | 21.5     |\n",
    "| facebook/nllb-200-distilled-1.3B | 68.75 | 44.44   | 89.08   | 37.4     |\n",
    "\n",
    "| Model                            | chrf2 | bleu    | comet22 | Time (s) |\n",
    "| -------------------------------- | ----- | ------- | ------- | -------- |\n",
    "| quickmt/quickmt-en-de            | 66.24 | 40.17   | 86.83   | 0.99     |\n",
    "| Helsinki-NLP/opus-mt-en-de       | 63.53 | 36.06   | 84.63   | 3.66     |\n",
    "| facebook/nllb-200-distilled-600M | 63.41 | 35.72   | 86.65   | 26.9     |\n",
    "| facebook/nllb-200-distilled-1.3B | 65.01 | 38.61   | 87.99   | 46.0     |\n",
    "| facebook/m2m100_418M             | 57.76 | 28.57   | 79.75   | 21.4     |\n",
    "| facebook/m2m100_1.2B             | 63.37 | 36.24   | 85.82   | 41.0     |\n",
    "\n",
    "\n",
    "| Model                            | chrf2 | bleu    | comet22 | Time (s) |\n",
    "| -------------------------------- | ----- | ------- | ------- | -------- |\n",
    "| quickmt/quickmt-ko-en            | 36.96 | 14.97   | 87.10   | 1.25     |\n",
    "| facebook/nllb-200-distilled-600M | 33.66 | 12.15   | 87.39   | 25.3     |\n",
    "| facebook/nllb-200-distilled-1.3B | 35.62 | 13.23   | 88.39   | 40.2     |\n",
    "| facebook/m2m100_418M             | 30.69 | 9.91    | 83.20   | 22.1     |\n",
    "| facebook/m2m100_1.2B             | 33.26 | 11.35   | 85.65   | 41.0     |\n",
    "\n",
    "| Model                            | chrf2 | bleu    | comet22 | Time (s) |\n",
    "| -------------------------------- | ----- | ------- | ------- | -------- |\n",
    "| quickmt/quickmt-ko-en            | 56.25 | 27.03   | 86.11   | 0.91     |\n",
    "| Helsinki-NLP/opus-mt-ko-en       | 50.39 | 20.78   | 83.06   | 3.81     |\n",
    "| facebook/nllb-200-distilled-600M | 55.04 | 26.53   | 85.83   | 21.0     |\n",
    "| facebook/nllb-200-distilled-1.3B | 57.56 | 29.61   | 87.24   | 37.2     |\n",
    "| facebook/m2m100_418M             | 50.65 | 20.75   | 82.07   | 18.2     |\n",
    "| facebook/m2m100_1.2B             | 62.35 | 24.59   | 85.15   | 34.7     |\n",
    "\n",
    "| Model                            | chrf2 | comet22 | Time (s) |\n",
    "| -------------------------------- | ----- | ------- | -------- |\n",
    "| quickmt/quickmt-en-ja            | 42.04 | 89.08   | 1.29     |\n",
    "| Helsinki-NLP/opus-mt-en-jap      | 6.41  | 62.91   | 7.35     |\n",
    "| facebook/nllb-200-distilled-600M | 30.00 | 86.64   | 28.4     |\n",
    "| facebook/nllb-200-distilled-1.3B | 32.38 | 88.02   | 37.2     |\n",
    "| facebook/m2m100_418M             | 32.73 | 85.09   | 24.7     |\n",
    "| facebook/m2m100_1.2B             | 35.83 | 87.78   | 45.7     |\n",
    "\n",
    "| Model                            | chrf2 | bleu    | comet22 | Time (s) |\n",
    "| -------------------------------- | ----- | ------- | ------- | -------- |\n",
    "| quickmt/quickmt-it-en            |  |    |    |      |\n",
    "| Helsinki-NLP/opus-mt-it-en       |  |    |    |      |\n",
    "| facebook/nllb-200-distilled-600M | 61.97 | 33.49   | 87.39   | 23.0     |\n",
    "| facebook/nllb-200-distilled-1.3B | 63.23 | 34.97   | 88.14   | 40.4     |\n",
    "| facebook/m2m100_418M             | 56.94 | 25.92   | 83.14   | 20.0     |\n",
    "| facebook/m2m100_1.2B             | 60.43 | 30.81   | 86.43   | 38.1     |\n",
    "\n",
    "| Model                            | chrf2 | bleu    | comet22 | Time (s) |\n",
    "| -------------------------------- | ----- | ------- | ------- | -------- |\n",
    "| quickmt/quickmt-en-it            |  |    |    |      |\n",
    "| Helsinki-NLP/opus-mt-en-it       |  |    |    |      |\n",
    "| facebook/nllb-200-distilled-600M |  |    |    |      |\n",
    "| facebook/nllb-200-distilled-1.3B |  |    |    |      |\n",
    "| facebook/m2m100_418M             |  |    |    |      |\n",
    "| facebook/m2m100_1.2B             |  |    |    |      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fdd6ef-ac08-4c1f-807d-d119cad746ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
